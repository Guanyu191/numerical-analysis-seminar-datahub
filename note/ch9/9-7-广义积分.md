# 9-7-广义积分 (Improper integrals)

这是一份数值计算学习笔记，参考了 Tobin A. Driscoll and Richard J. Braun 的教材 [*Fundamentals of Numerical Computation* (2023)](https://tobydriscoll.net/fnc-julia/home.html).

> 这份笔记主要是翻译了原文内容，并删改或重新表述部分内容，希望能进一步减少初学者的学习障碍.

**#1 什么是广义积分**

当积分区间无界，或被积函数本身无界时，这个积分称为 **广义积分 (improper integral)**. 广义积分在数值计算上会带来一些特别的挑战.

**#2 无穷区间与直接截断**

当积分区间是 $(-\infty,\infty)$ 时，为了让积分有限，被积函数必须在 $x\to\pm\infty$ 时衰减. 这自然会让我们想到用截断来逼近：

$$
\int_{-\infty}^{\infty} f(x)\,dx \approx \int_{-M}^{M} f(x)\,dx.
$$

右边可以用梯形公式或自适应积分器做有限离散化. 但直接截断可能效率很低.

> **Example:** Truncation can be extremely inefficient
> Consider $f(x)=1/(1+x^2)$. Then
> $$
> \int_{-\infty}^{\infty}\frac{1}{1+x^2}\,dx=\pi.
> $$
> For large $M$,
> $$
> \int_{M}^{\infty} f(x)\,dx \approx \int_{M}^{\infty} x^{-2}\,dx = M^{-1}.
> $$
> The same estimate applies to $(-\infty,-M)$. To get eight digits of accuracy, we would need $M>2\times 10^8$.

**#3 双指数变换 (double exponential transformation)**

为了比直接截断更好，我们希望让函数在新变量下更快衰减. 实际上这意味着做变量代换 $x=x(t)$. 如果 $|x(t)|$ 在 $|t|\to\infty$ 时增长得很快，那么 $f(x(t))$ 在 $t$ 变量下就会衰减得更快.

一种常用选择是

$$
x(t)=\sinh(\sinh t).
$$

注意当 $t\to\pm\infty$ 时，

$$
\lvert\sinh(t)\rvert \sim \frac{1}{2}e^{|t|},
\qquad
x(t) \approx \pm \frac{1}{2}\exp\left(\frac{1}{2}e^{|t|}\right).
$$

因此它经常被称为 **双指数变换**.

由链式法则，

$$
\int_{-\infty}^{\infty} f(x)\,dx
=
\int_{-\infty}^{\infty} f(x(t))\frac{dx}{dt}\,dt
=
\int_{-\infty}^{\infty} f(x(t))\cosh(\sinh t)\cosh t\,dt.
$$

虽然 $\cosh(\sinh t)\cosh t$ 这一项会双指数增长，但 $f(x(t))$ 在 $t$ 变量下往往衰减得更快，最终乘积仍可能是双指数衰减.

> **Demo:** A transformed integrand with double exponential decay
> We compare the original and transformed integrands for $f(x)=1/(1+x^2)$, illustrating why truncating in `t` can be much more effective.
>
> ```Python
> import numpy as np
> import matplotlib.pyplot as plt
>
> f = lambda x: 1.0 / (1.0 + x * x)
> x = lambda t: np.sinh(np.sinh(t))
> dx_dt = lambda t: np.cosh(t) * np.cosh(np.sinh(t))
> g = lambda t: f(x(t)) * dx_dt(t)
>
> xs = np.linspace(-4.0, 4.0, 2000)
> ts = np.linspace(-4.0, 4.0, 2000)
>
> fig, ax = plt.subplots(2, 1, figsize=(6, 4), sharex=False)
> ax[0].semilogy(xs, f(xs))
> ax[0].set_title("Original integrand")
> ax[0].grid(True, which="both", alpha=0.3)
> ax[1].semilogy(ts, np.abs(g(ts)))
> ax[1].set_title("Transformed integrand")
> ax[1].grid(True, which="both", alpha=0.3)
> plt.tight_layout()
> plt.show()
> ```
>
> This suggests that integrating in `t` over a modest interval (e.g. from -4 to 4) can capture essentially all values above machine epsilon.

**#4 双指数积分：无穷区间**

双指数方法的一个实现方式是：在 $t$ 空间上做自适应积分，并自动把积分区间截断为 $[-M,M]$，直到端点处的被积函数足够小 (相对于误差容忍度).

> **Demo:** Double exponential integration on $(-\\infty,\\infty)$
> We implement the method by wrapping an adaptive integrator on a truncated `t`-interval.
>
> ```Python
> import numpy as np
> from math import isfinite
>
> def intadapt(f, a, b, tol):
>     # A minimal adaptive Simpson implementation (recursive).
>     def simpson(f, a, b):
>         c = 0.5 * (a + b)
>         h = b - a
>         return (h / 6.0) * (f(a) + 4.0 * f(c) + f(b))
>
>     def rec(f, a, b, fa, fb, fc, S, tol, depth):
>         c = 0.5 * (a + b)
>         left_c = 0.5 * (a + c)
>         right_c = 0.5 * (c + b)
>         f_left_c = f(left_c)
>         f_right_c = f(right_c)
>         S_left = (c - a) / 6.0 * (fa + 4.0 * f_left_c + fc)
>         S_right = (b - c) / 6.0 * (fc + 4.0 * f_right_c + fb)
>         if depth <= 0 or abs(S_left + S_right - S) <= 15.0 * tol:
>             return S_left + S_right + (S_left + S_right - S) / 15.0
>         return rec(f, a, c, fa, fc, f_left_c, S_left, tol / 2.0, depth - 1) + rec(
>             f, c, b, fc, fb, f_right_c, S_right, tol / 2.0, depth - 1
>         )
>
>     fa, fb = f(a), f(b)
>     c = 0.5 * (a + b)
>     fc = f(c)
>     S = simpson(f, a, b)
>     return rec(f, a, b, fa, fb, fc, S, tol, depth=20)
>
> def intinf(f, tol):
>     x = lambda t: np.sinh(np.sinh(t))
>     dx_dt = lambda t: np.cosh(t) * np.cosh(np.sinh(t))
>     g = lambda t: f(x(t)) * dx_dt(t)
>
>     M = 3.0
>     while abs(g(-M)) > tol / 100.0 or abs(g(M)) > tol / 100.0:
>         M += 0.5
>         if not isfinite(x(M)):
>             # Function may not decay fast enough.
>             M -= 0.5
>             break
>
>     I = intadapt(g, -M, M, tol)
>     return I
> ```

> **Note:** 这里只给了一个最小可运行的自适应 Simpson 版本，用来体现方法结构. 更稳健的实现会更复杂 (例如更严格的停止准则、节点复用、以及数值溢出处理).

**#5 端点奇异性**

如果 $f$ 在某个积分端点附近趋于无穷大，那么积分可能仍然是有限的，也可能发散. 若该奇异性是可积的，那么靠近奇异点的一段区间通常需要比其他区域更细的分辨率.

考虑

$$
\int_{0}^{1} f(x)\,dx,
$$

其中 $f$ 或 $f$ 的某个导数在左端点 0 处无界. 我们用变量代换

$$
x(t)=\frac{2}{1+\exp(2\sinh t)}.
$$

它满足 $x(0)=1$ 且当 $t\to\infty$ 时 $x\to 0^+$，从而把积分区间变成 $t\in(0,\infty)$，并把奇异点移到无穷远处. 链式法则给出

$$
\int_{0}^{1} f(x)\,dx
=
\int_{0}^{\infty} f(x(t))\frac{dx}{dt}\,dt
=
\int_{0}^{\infty} f(x(t))\frac{\cosh t}{\cosh(\sinh t)^2}\,dt.
$$

这里 $f$ 与 $\cosh t$ 的增长，会被 $\cosh(\sinh t)^2$ 的双指数分母抵消，从而允许我们在 $t$ 方向做截断.

> **Demo:** Double exponential integration for endpoint singularities
> We implement the transformed integral on a truncated interval $(0,M)$ and apply adaptive integration.
>
> ```Python
> import numpy as np
> from math import isfinite
>
> def intsing(f, tol):
>     x = lambda t: 2.0 / (1.0 + np.exp(2.0 * np.sinh(t)))
>     dx_dt = lambda t: np.cosh(t) / (np.cosh(np.sinh(t)) ** 2)
>     g = lambda t: f(x(t)) * dx_dt(t)
>
>     M = 3.0
>     while abs(g(M)) > tol / 100.0:
>         M += 0.5
>         if x(M) == 0.0:
>             # Function may grow too rapidly.
>             M -= 0.5
>             break
>
>     I = intadapt(g, 0.0, M, tol)
>     return I
> ```

> **Demo:** A simple singular integral
> We compute $\\int_{0}^{0.01} \\frac{1}{\\sqrt{x}}\\,dx$. First rewrite it to fit the $(0,1)$ setup by using $s=100t$:
> $$
> \\int_{0}^{0.01}\\frac{1}{\\sqrt{x}}\\,dx
> =
> \\int_{0}^{1}\\frac{1}{10\\sqrt{s}}\\,ds
> =
> 0.2.
> $$
>
> ```Python
> import numpy as np
>
> f = lambda s: 1.0 / (10.0 * np.sqrt(s))
> I = intsing(f, tol=1e-10)
> print("estimate", I, "error", abs(I - 0.2))
> ```
>
> The double exponential method can reach high accuracy with far fewer nodes than direct truncation in the original variable.

**#6 小结**

双指数积分是一种通用的广义积分数值方法，通常会比在原变量里直接做区间截断更有效. 当然，也存在针对特定奇异性类型的专门方法能做得更好，但它们往往需要更多的解析工作才能正确使用.
