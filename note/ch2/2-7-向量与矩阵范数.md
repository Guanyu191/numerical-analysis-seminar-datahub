# 2-7-向量与矩阵范数 (Vector and matrix norms)

这是一份数值计算学习笔记，参考了 Tobin A. Driscoll and Richard J. Braun 的教材 [*Fundamentals of Numerical Computation* (2023)](https://tobydriscoll.net/fnc-julia/home.html).

> 这份笔记主要是翻译了原文内容，并删改或重新表述部分内容，希望能进一步减少初学者的学习障碍.

**#1 向量范数**

到目前为止，我们对矩阵与向量的操作更多是代数层面的. 如果要进一步分析算法误差与稳定性，我们需要一个工具来 **度量 "大小"**：不是行数与列数的大小，而是幅度或距离的大小.

对向量，我们用一个范数 $\|\cdot\|$，它把 $\mathbb{R}^n$ 映射到 $\mathbb{R}$，并满足对任意向量 $\mathbf{x},\mathbf{y}$ 与标量 $\alpha$：

$$
\begin{aligned}
\|\mathbf{x}\| &\ge 0,\\
\|\mathbf{x}\| &= 0 \Longleftrightarrow \mathbf{x}=\mathbf{0},\\
\|\alpha\mathbf{x}\| &= |\alpha|\,\|\mathbf{x}\|,\\
\|\mathbf{x}+\mathbf{y}\| &\le \|\mathbf{x}\|+\|\mathbf{y}\|.
\end{aligned}
$$

最后一个性质称为三角不等式. 直觉上，我们可以把 $\|\mathbf{x}\|=\|\mathbf{x}-\mathbf{0}\|$ 看成 $\mathbf{x}$ 到原点的距离，把 $\|\mathbf{x}-\mathbf{y}\|$ 看成 $\mathbf{x}$ 到 $\mathbf{y}$ 的距离.

这一章里最常用的是下面三个向量范数.

> **Definition:** **Common vector norms.**
> 
> 2-norm:
> $$
> \|\mathbf{x}\|_2 = \left(\sum_{i=1}^{n}|x_i|^2\right)^{1/2} = \sqrt{\mathbf{x}^{T}\mathbf{x}}.
> $$
> $\infty$-norm or max-norm:
> $$
> \|\mathbf{x}\|_\infty = \max_{i=1,\dots,n}|x_i|.
> $$
> 1-norm:
> $$
> \|\mathbf{x}\|_1 = \sum_{i=1}^{n}|x_i|.
> $$

2-norm 对应我们熟悉的欧氏距离.

在任意范数下，满足 $\|\mathbf{x}\|=1$ 的向量称为单位向量. 对任意非零向量 $\mathbf{v}$，我们都可以通过归一化得到一个单位向量：$\mathbf{x}=\mathbf{v}/\|\mathbf{v}\|$. 因此我们也可以把 $\mathbf{v}$ 写成 **"幅度-方向"** 的形式：

$$
\mathbf{v}=\|\mathbf{v}\|\cdot \frac{\mathbf{v}}{\|\mathbf{v}\|}.
$$

> **Demo:** Computing vector norms and a normalization (NumPy).
> ```Python
> import numpy as np
>
> x = np.array([2, -3, 1, -1], dtype=float)
> print("||x||_2 =", np.linalg.norm(x))
> print("||x||_inf =", np.linalg.norm(x, np.inf))
> print("||x||_1 =", np.linalg.norm(x, 1))
>
> # Normalize in the infinity norm.
> x_unit = x / np.linalg.norm(x, np.inf)
> print("x / ||x||_inf =", x_unit)
> print("||x_unit||_inf =", np.linalg.norm(x_unit, np.inf))
> ```
> A unit vector has norm 1 in the chosen norm.

> **Note:** 在 NumPy 里，`np.linalg.norm(x)` 对向量默认是 2-norm；`np.linalg.norm(x, 1)` 是 1-norm；`np.linalg.norm(x, np.inf)` 是 $\infty$-norm.

**#2 范数与收敛**

> **Note:** 许多情况下，写 $\|\mathbf{x}\|$ 默认指 2-norm. 但在这一节里，我们会把它理解为 "某个未指定的向量范数"，直到需要明确指定下标为止.

我们说一列向量 $\mathbf{x}_1,\mathbf{x}_2,\dots$ 收敛到 $\mathbf{x}$，意思就是

$$
\lim_{k\to\infty}\|\mathbf{x}_k-\mathbf{x}\|=0.
$$

按定义，序列在 $\infty$-norm 下收敛当且仅当按分量收敛. 在 **有限维空间** 里，更强的是：只要在某一个范数下收敛，就会在所有范数下收敛 **(有限维空间的范数等价性)**.

> **Theorem:** **Norm equivalence.**
> In a finite-dimensional space, convergence in any norm implies convergence in all norms.

> **Note:** 在有限维空间里，"等价" 以下面的不等式来刻画：对任意两个范数 $\|\cdot\|_a,\|\cdot\|_b$，都存在常数 $c,C>0$ 使得对任意 $\mathbf{x}$ 有 $c\|\mathbf{x}\|_a\le \|\mathbf{x}\|_b\le C\|\mathbf{x}\|_a$. 例如对任意 $\mathbf{x}\in\mathbb{R}^n$，
> $$
> \|\mathbf{x}\|_\infty \le \|\mathbf{x}\|_2 \le \sqrt{n}\,\|\mathbf{x}\|_\infty,
> \qquad
> \|\mathbf{x}\|_2 \le \|\mathbf{x}\|_1 \le \sqrt{n}\,\|\mathbf{x}\|_2.
> $$

**#3 矩阵范数**

尽管矩阵看起来是二维对象，我们也可以把它看成一个向量：把各列依次堆起来. 这样一来，向量 2-norm 会诱导出一个矩阵范数，称为 **Frobenius** 范数：

$$
\|\mathbf{A}\|_F=\left(\sum_{i,j}|A_{ij}|^2\right)^{1/2}.
$$

> **Note:** 这里说的 "把各列堆起来" 是一种数学上的定义方式 (我们甚至可以理解为把矩阵 "拉直" 成向量)，不等价于矩阵在内存中的存储顺序. 例如 NumPy 通常按 row-major 存储，Julia/MATLAB 常见 column-major，但这些实现细节不会改变 Frobenius 范数或诱导范数的定义.


不过在分析线性系统算法时，更常用的矩阵范数来自 **"把矩阵当成线性算子"** 的视角.

> **Definition:** **Induced matrix norm.**
> Given a vector norm $\|\cdot\|_p$, we define an induced matrix norm for any $m\times n$ matrix $\mathbf{A}$ as
> $$
> \|\mathbf{A}\|_p = \max_{\|\mathbf{x}\|_p = 1}\|\mathbf{A}\mathbf{x}\|_p = \max_{\mathbf{x}\ne \mathbf{0}} \frac{\|\mathbf{A}\mathbf{x}\|_p}{\|\mathbf{x}\|_p}.
> $$

当我们用一个未指定的诱导范数时，后续仍写成 $\|\mathbf{A}\|$；在离开这一节后，不带下标的矩阵范数默认指 2-norm.

诱导范数之所以重要，是因为它立刻带来一组基本不等式.

> **Theorem:** **Norm inequalities.**
> Let $\|\cdot\|$ designate a matrix norm and the vector norm that induced it. Then for all matrices and vectors of compatible sizes,
> $$
> \|\mathbf{A}\mathbf{x}\|\le \|\mathbf{A}\|\,\|\mathbf{x}\|.
> $$
> For all matrices of compatible sizes,
> $$
> \|\mathbf{A}\mathbf{B}\|\le \|\mathbf{A}\|\,\|\mathbf{B}\|.
> $$
> For a square matrix $\mathbf{A}$,
> $$
> \|\mathbf{A}^k\|\le \|\mathbf{A}\|^k \quad \text{for any integer } k\ge 0.
> $$

从几何角度看，诱导范数把 "单位球面" 上的所有向量 $\mathbf{x}$ 映射成 $\mathbf{A}\mathbf{x}$，而 $\|\mathbf{A}\|$ 正是 "能包住所有 $\mathbf{A}\mathbf{x}$ 的最小球面" 的半径.

对 1-norm 与 $\infty$-norm，还存在直接从矩阵元素算出来的等价公式.

> **Theorem:** **Matrix $\infty$-norm and 1-norm.**
> $$
> \|\mathbf{A}\|_\infty = \max_{1\le i\le n}\sum_{j=1}^{n}|A_{ij}|,
> \qquad
> \|\mathbf{A}\|_1 = \max_{1\le j\le n}\sum_{i=1}^{n}|A_{ij}|.
> $$

> **Note:** 这里 **$\|\mathbf{A}\|_\infty$ 是 "最大行和"**，**$\|\mathbf{A}\|_1$ 是 "最大列和"**. 一个记忆方式是：$\|\mathbf{A}\|_\infty$ 看行 (一行一行数)，$\|\mathbf{A}\|_1$ 看列 (一列一列数). 这两个公式对应的是诱导的 $\infty$-norm 与 1-norm.

> **Demo:** Computing matrix norms and verifying the 1/∞ formulas.
> ```Python
> import numpy as np
>
> A = np.array([[2, 0], [1, -1]], dtype=float)
>
> print("||A||_F =", np.linalg.norm(A))            # Frobenius
> print("||A||_2 =", np.linalg.norm(A, 2))         # induced 2-norm (spectral norm)
> print("||A||_1 =", np.linalg.norm(A, 1))
> print("||A||_inf =", np.linalg.norm(A, np.inf))
>
> colsum_max = np.max(np.sum(np.abs(A), axis=0))
> rowsum_max = np.max(np.sum(np.abs(A), axis=1))
> print("max column sum =", colsum_max)
> print("max row sum =", rowsum_max)
> ```
> For induced 1- and ∞-norms, the results match the maximum column/row sums in absolute value.

> **Note:** 在 NumPy 里，`np.linalg.norm(A)` 对矩阵默认给的是 Frobenius 范数 $\|\mathbf{A}\|_F$，不是诱导 2-norm. 注意，向量的 2-norm 与矩阵的诱导 2-norm 不是一回事. 若想计算 **诱导 2-norm**，需要显式写 `np.linalg.norm(A, 2)`.

最后用一个图来理解 $\|\mathbf{A}\|_2$ 的几何含义. 在 $\mathbb{R}^2$ 中，单位圆上的点构成所有满足 $\|\mathbf{x}\|_2=1$ 的向量集合；把这些点都做一次映射 $\mathbf{x}\mapsto \mathbf{A}\mathbf{x}$，得到的是一个椭圆；而这个椭圆恰好被半径为 $\|\mathbf{A}\|_2$ 的圆 "刚好包住".

> **Note:** 这就是刚才说的 $\|\mathbf{A}\|_2$ 是 "能包住所有 $\mathbf{A}\mathbf{x}$ 的最小球面" 的半径.

> **Demo:** Geometric view of the matrix 2-norm in $\mathbb{R}^2$.
> ```Python
> import numpy as np
> import matplotlib.pyplot as plt
>
> A = np.array([[2, 0], [1, -1]], dtype=float)
> norm2 = np.linalg.norm(A, 2)
>
> theta = np.linspace(0, 2 * np.pi, 601)
> x = np.vstack([np.cos(theta), np.sin(theta)])  # 2 x m, unit circle samples
> Ax = A @ x
>
> fig, axes = plt.subplots(1, 2, figsize=(8, 4))
> axes[0].plot(x[0], x[1])
> axes[0].set_aspect("equal")
> axes[0].set_title("Unit circle")
>
> axes[1].plot(Ax[0], Ax[1], label="image")
> axes[1].plot(norm2 * x[0], norm2 * x[1], "--", label="radius ||A||_2")
> axes[1].set_aspect("equal")
> axes[1].set_title("Image under x -> A x")
> axes[1].legend()
>
> plt.show()
> ```
> The ellipse is enclosed by the circle of radius $\|\mathbf{A}\|_2$.

这个几何解释不等于一个实用的计算方法. 与 1-norm 或 $\infty$-norm 不同，**$\|\mathbf{A}\|_2$ 没有一个像 "最大行和 / 最大列和" 那样的简单元素公式**，它的计算会在后续章节 (尤其是与特征值相关的章节) 里再讨论.
