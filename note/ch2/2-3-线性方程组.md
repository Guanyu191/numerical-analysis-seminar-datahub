# 2-3-线性方程组 (Linear systems)

这是一份数值计算学习笔记，参考了 Tobin A. Driscoll and Richard J. Braun 的教材 [*Fundamentals of Numerical Computation* (2023)](https://tobydriscoll.net/fnc-julia/home.html).

> 这份笔记主要是翻译了原文内容，并删改或重新表述部分内容，希望能进一步减少初学者的学习障碍.

**#1 线性系统的基本问题**

本章要处理的核心问题是：给定一个 $n\times n$ 方阵 $\mathbf{A}$ 与一个 $n$ 维向量 $\mathbf{b}$，求一个 $n$ 维向量 $\mathbf{x}$ 使得

$$
\mathbf{A}\mathbf{x}=\mathbf{b}.
$$

把方程逐行展开，就是

$$
\begin{aligned}
A_{11}x_1+A_{12}x_2+\cdots+A_{1n}x_n &= b_1,\\
A_{21}x_1+A_{22}x_2+\cdots+A_{2n}x_n &= b_2,\\
&\vdots\\
A_{n1}x_1+A_{n2}x_2+\cdots+A_{nn}x_n &= b_n.
\end{aligned}
$$

如果 $\mathbf{A}$ 可逆，那么从数学表达式上，解就是 $\mathbf{x}=\mathbf{A}^{-1}\mathbf{b}$，因为

$$
\mathbf{A}^{-1}\mathbf{b}=\mathbf{A}^{-1}(\mathbf{A}\mathbf{x})=(\mathbf{A}^{-1}\mathbf{A})\mathbf{x}=\mathbf{I}\mathbf{x}=\mathbf{x}.
$$

当 $\mathbf{A}$ 奇异时 (可以先简单认为 $\mathbf{A}$ 的逆不存在)，$\mathbf{A}\mathbf{x}=\mathbf{b}$ 可能无解，也可能有无穷多解.

> **Example:** If we define
> $$
> \mathbf{S}=\begin{bmatrix}0&1\\0&0\end{bmatrix},
> $$
> then it is easy to check that for any real value of $\alpha$ we have
> $$
> \mathbf{S}\begin{bmatrix}\alpha\\1\end{bmatrix}=\begin{bmatrix}1\\0\end{bmatrix}.
> $$
> Hence the linear system $\mathbf{S}\mathbf{x}=\mathbf{b}$ with $\mathbf{b}=\begin{bmatrix}1\\0\end{bmatrix}$ has infinitely many solutions. For most other choices of $\mathbf{b}$, the system has no solution.

**#2 不要用逆矩阵来解线性系统**

逆矩阵在推导与讨论里非常重要，但从原始矩阵元素直接算出逆矩阵并不容易. 更关键的是：即使我们想解 $\mathbf{A}\mathbf{x}=\mathbf{b}$，显式求 $\mathbf{A}^{-1}$ 也几乎从来不是最好的计算方式.

对于解线性系统而言，先求逆再乘 $\mathbf{b}$ 通常比标准算法更慢. 实际计算里我们更希望直接调用线性系统求解器.

> **Note:** 在 **2-1-多项式插值** 里，我们已经用过线性系统求解器：通过求解 Vandermonde 系统 $\mathbf{V}\mathbf{c}=\mathbf{y}$ 得到插值多项式的系数向量 $\mathbf{c}$.

> **Demo:** Solving $\mathbf{A}\mathbf{x}=\mathbf{b}$ and checking the residual.
> ```Python
> import numpy as np
>
> A = np.array([[1, 0, -1], [2, 2, 1], [-1, -3, 0]], dtype=float)
> b = np.array([1, 2, 3], dtype=float)
>
> x = np.linalg.solve(A, b)
> r = b - A @ x
> print("x =", x)
> print("residual =", r)
>
> # A singular example.
> A_sing = np.array([[0, 1], [0, 0]], dtype=float)
> b_sing = np.array([1, -1], dtype=float)
> try:
>     np.linalg.solve(A_sing, b_sing)
> except np.linalg.LinAlgError as e:
>     print("solve failed:", e)
>
> print("rank(A_sing) =", np.linalg.matrix_rank(A_sing))
> ```
> The residual is ideally at the level of machine precision relative to the size of the data.

残差 $\mathbf{r}=\mathbf{b}-\mathbf{A}\mathbf{x}$ 是检验解好不好的一种自然方式. 在浮点数运算里，我们通常不期待残差精确为零，而只期待它能达到与 $\epsilon_{\rm mach}$ 同数量级的水平 (见 **1-1-浮点数**).

奇异性检测在数值上类似于 "判断两个浮点数是否严格相等"：由于舍入误差，"几乎奇异" 的矩阵可能难以被检测出来. 在 **2-8-线性系统的条件数** 里我们会用更稳健的方式描述这种情况.

> **Note:** `np.linalg.matrix_rank` 用 SVD 的阈值来估计秩. 当矩阵接近奇异时，"秩到底是多少" 会变成一个与阈值选择强相关的问题，因此它不适合作为稳健的奇异性判定标准.

**#3 三角线性系统**

对于三角矩阵，解线性系统的过程尤其直观. 例如考虑一个下三角系统

$$
\begin{bmatrix}
4&0&0&0\\
3&-1&0&0\\
-1&0&3&0\\
1&-1&-1&2
\end{bmatrix}
\mathbf{x}
=
\begin{bmatrix}
8\\
5\\
0\\
1
\end{bmatrix}.
$$

第一行给出 $4x_1=8$，因此 $x_1=2$. 第二行给出 $3x_1-x_2=5$，代入 $x_1$ 就得到 $x_2=1$. 第三行给出 $-x_1+3x_3=0$，得到 $x_3=2/3$. 最后一行给出 $x_1-x_2-x_3+2x_4=1$，得到 $x_4=1/3$. 这种从上到下逐个求解未知量的过程称为 **forward substitution** (前代).

一般地，对 $4\times 4$ 下三角系统 $\mathbf{L}\mathbf{x}=\mathbf{b}$，前代给出

$$
\begin{bmatrix}
L_{11}&0&0&0\\
L_{21}&L_{22}&0&0\\
L_{31}&L_{32}&L_{33}&0\\
L_{41}&L_{42}&L_{43}&L_{44}
\end{bmatrix}
\begin{bmatrix}
x_1\\
x_2\\
x_3\\
x_4
\end{bmatrix}
=
\begin{bmatrix}
b_1\\
b_2\\
b_3\\
b_4
\end{bmatrix}
, \qquad
\begin{aligned}
x_1 &= \frac{b_1}{L_{11}},\\
x_2 &= \frac{b_2-L_{21}x_1}{L_{22}},\\
x_3 &= \frac{b_3-L_{31}x_1-L_{32}x_2}{L_{33}},\\
x_4 &= \frac{b_4-L_{41}x_1-L_{42}x_2-L_{43}x_3}{L_{44}}.
\end{aligned}
$$

对上三角系统 $\mathbf{U}\mathbf{x}=\mathbf{b}$，对应的过程是 **backward substitution** (回代)：从最后一个分量开始往回求. 在 $4\times 4$ 的情形中，

$$
\begin{bmatrix}
U_{11}&U_{12}&U_{13}&U_{14}\\
0&U_{22}&U_{23}&U_{24}\\
0&0&U_{33}&U_{34}\\
0&0&0&U_{44}
\end{bmatrix}
\begin{bmatrix}
x_1\\
x_2\\
x_3\\
x_4
\end{bmatrix}
=
\begin{bmatrix}
b_1\\
b_2\\
b_3\\
b_4
\end{bmatrix}
, \qquad
\begin{aligned}
x_4 &= \frac{b_4}{U_{44}},\\
x_3 &= \frac{b_3-U_{34}x_4}{U_{33}},\\
x_2 &= \frac{b_2-U_{23}x_3-U_{24}x_4}{U_{22}},\\
x_1 &= \frac{b_1-U_{12}x_2-U_{13}x_3-U_{14}x_4}{U_{11}}.
\end{aligned}
$$

> **Note:** 当主对角线上出现 0 元素，前代和回代就出问题了.

> **Theorem:** **Triangular singularity.**
> A triangular matrix is singular if and only if at least one of its diagonal elements is zero.

**#4 前代与回代的实现**

以 $\mathbf{L}\mathbf{x}=\mathbf{b}$ 的前代为例，它是一个顺序过程：我们按 $i=1,2,\dots,n$ 计算 $x_i$. 在计算 $x_i$ 时，需要累加 $\sum_{j=1}^{i-1}L_{ij}x_j$ 这样的部分和，因此实现上常见的方式是 "外层循环遍历 $i$，内层循环遍历 $j$".

当 $i=1$ 时，求和范围是空的，最稳妥的写法是单独处理 $x_1$，然后从 $i=2$ 开始循环.

> **Demo:** Forward substitution (`forwardsub`).
> ```Python
> import numpy as np
>
> def forwardsub(L, b):
>     """Solve L x = b for lower triangular L by forward substitution."""
>     n = L.shape[0]
>     x = np.zeros(n, dtype=float)
>     x[0] = b[0] / L[0, 0]
>     for i in range(1, n):
>         s = np.dot(L[i, :i], x[:i])
>         x[i] = (b[i] - s) / L[i, i]
>     return x
> ```
> This follows the sequential structure of forward substitution.

回代实现与前代几乎完全对称：先处理最后一个分量，然后让 $i$ 从 $n-1$ 递减到 1.

> **Demo:** Backward substitution (`backsub`).
> ```Python
> import numpy as np
>
> def backsub(U, b):
>     """Solve U x = b for upper triangular U by backward substitution."""
>     n = U.shape[0]
>     x = np.zeros(n, dtype=float)
>     x[-1] = b[-1] / U[-1, -1]
>     for i in range(n - 2, -1, -1):
>         s = np.dot(U[i, i + 1 :], x[i + 1 :])
>         x[i] = (b[i] - s) / U[i, i]
>     return x
> ```
> This is the backward analogue of forward substitution.

**#5 一个关于精度损失的提示**

我们用一个数值实验来检验前代 / 回代，并观察一个并不显眼但很重要的现象：即使系统矩阵是三角的，回代过程仍可能因为 subtractive cancellation 而损失精度.

> **Demo:** Testing substitution and observing cancellation.
> ```Python
> import numpy as np
>
> def forwardsub(L, b):
>     """Solve L x = b for lower triangular L by forward substitution."""
>     n = L.shape[0]
>     x = np.zeros(n, dtype=float)
>     x[0] = b[0] / L[0, 0]
>     for i in range(1, n):
>         s = np.dot(L[i, :i], x[:i])
>         x[i] = (b[i] - s) / L[i, i]
>     return x
>
> def backsub(U, b):
>     """Solve U x = b for upper triangular U by backward substitution."""
>     n = U.shape[0]
>     x = np.zeros(n, dtype=float)
>     x[-1] = b[-1] / U[-1, -1]
>     for i in range(n - 2, -1, -1):
>         s = np.dot(U[i, i + 1 :], x[i + 1 :])
>         x[i] = (b[i] - s) / U[i, i]
>     return x
>
> rng = np.random.default_rng(0)
> A = rng.integers(1, 10, size=(5, 5)).astype(float)
> L = np.tril(A)
> b = np.ones(5)
> x = forwardsub(L, b)
> print("residual =", b - L @ x)
>
> # Engineer an upper triangular system with known exact solution.
> n = 5
> alpha = 0.3
> x_exact = np.ones(n)
> for beta in [2.2, 1e12]:
>     U = np.eye(n)
>     U[np.arange(n - 1), np.arange(1, n)] = -1.0
>     U[0, [3, 4]] = [alpha - beta, beta]
>     b = np.array([alpha, 0, 0, 0, 1], dtype=float)
>     x = backsub(U, b)
>     print("beta =", beta, "err =", x - x_exact)
> ```
> For large `beta`, the first component loses many digits due to subtractive cancellation.

> **Note:** 当上面 Demo 的 $|\beta|$ 很大而 $|\alpha|$ 很小时，回代里对 $x_1$ 的求解会包含 $(\alpha-\beta)+\beta$ 这样的计算，这会触发 **subtractive cancellation** (消去)，使得有限精度下的有效数字大量丢失.

> **Note:** 上面的现象提示我们：线性系统问题本身可能具有很大的条件数，从而使 "解不准" 在浮点运算里变得不可避免. 在进入 **2-8-线性系统的条件数** 之前，我们还需要先讨论怎样求解一般线性系统，而不仅仅是三角系统.
