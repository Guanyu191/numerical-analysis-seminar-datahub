# 2-8-线性系统的条件数 (Conditioning of linear systems)

这是一份数值计算学习笔记，参考了 Tobin A. Driscoll and Richard J. Braun 的教材 [*Fundamentals of Numerical Computation* (2023)](https://tobydriscoll.net/fnc-julia/home.html).

> 这份笔记主要是翻译了原文内容，并删改或重新表述部分内容，希望能进一步减少初学者的学习障碍.

**#1 从扰动推到矩阵条件数**

我们现在要讨论 "解线性系统" 这个问题本身的条件数. 对问题

$$
\mathbf{A}\mathbf{x}=\mathbf{b},
$$

数据是 $(\mathbf{A},\mathbf{b})$，结果是 $\mathbf{x}$. 因为输入与输出都是向量或矩阵，我们需要用范数来度量它们的相对变化.

在 **1-2-问题与条件数** 中，我们定义条件数的原始想法是：**"结果相对变化"** 与 **"数据相对变化"** 的比值. 简单起见，我们先假设 $\mathbf{A}$ 固定，只扰动右端项 $\mathbf{b}$. 设

$$
\mathbf{A}(\mathbf{x}+\mathbf{h})=\mathbf{b}+\mathbf{d}.
$$

直觉来看，条件数的定义是 "输出相对变化除以输入相对变化"，也就是

$$
\frac{\|\mathbf{h}\|/\|\mathbf{x}\|}{\|\mathbf{d}\|/\|\mathbf{b}\|}.
$$

由

$$
\mathbf{A}\mathbf{x}+\mathbf{A}\mathbf{h}=\mathbf{b}+\mathbf{d}
\quad\Longrightarrow\quad
\mathbf{A}\mathbf{h}=\mathbf{d}
\quad\Longrightarrow\quad
\mathbf{h}=\mathbf{A}^{-1}\mathbf{d},
$$

以及诱导范数的不等式 $\|\mathbf{A}\mathbf{x}\|\le \|\mathbf{A}\|\,\|\mathbf{x}\|$，我们得到

$$
\|\mathbf{h}\| \le \|\mathbf{A}^{-1}\|\,\|\mathbf{d}\|,
\qquad
\|\mathbf{b}\|=\|\mathbf{A}\mathbf{x}\|\le \|\mathbf{A}\|\,\|\mathbf{x}\|.
$$

把它们代回相对变化比，就得到上界

$$
\frac{\|\mathbf{h}\|/\|\mathbf{x}\|}{\|\mathbf{d}\|/\|\mathbf{b}\|}
\le
\|\mathbf{A}^{-1}\|\,\|\mathbf{A}\|.
$$

> **Note:** 详细步骤
> $$
> \frac{\|\mathbf{h}\|/\|\mathbf{x}\|}{\|\mathbf{d}\|/\|\mathbf{b}\|}
> = 
> \frac{\|\mathbf{h}\| \|\mathbf{b}\|}{\|\mathbf{d}\| \|\mathbf{x}\|}
> \le
> \frac{\big(\|\mathbf{A}^{-1}\|\,\|\mathbf{d}\|\big) \big(\|\mathbf{A}\|\,\|\mathbf{x}\|\big)}{\|\mathbf{d}\| \|\mathbf{x}\|}
> =
> \|\mathbf{A}^{-1}\|\,\|\mathbf{A}\|.
> $$

这个上界自然地引出了矩阵条件数的定义.

> **Definition:** **Matrix condition number.**
> The matrix condition number of an invertible square matrix $\mathbf{A}$ is
> $$
> \kappa(\mathbf{A})=\|\mathbf{A}^{-1}\|\,\|\mathbf{A}\|.
> $$
> This value depends on the choice of norm; a subscript on $\kappa$ such as $1$, $2$, or $\infty$ is used if clarification is needed. If $\mathbf{A}$ is singular, we define $\kappa(\mathbf{A}) = \infty$.

**#2 主要结论**

矩阵的条件数 $\kappa(\mathbf{A})$ 也就是解线性系统 $\mathbf{A}\mathbf{x}=\mathbf{b}$ 这个问题的条件数. 即便刚才的推导只允许扰动 $\mathbf{b}$，但线性系统的条件数结论同样适用于扰动 $\mathbf{A}$.

> **Theorem:** **Conditioning of linear systems.**
> If $\mathbf{A}(\mathbf{x} + \Delta \mathbf{x}) = \mathbf{b}+\Delta \mathbf{b}$, then
> $$
> \frac{\|\Delta \mathbf{x}\|}{\|\mathbf{x}\|} \le \kappa(\mathbf{A})\,\frac{\|\Delta \mathbf{b}\|}{\|\mathbf{b}\|}.
> $$
> If $(\mathbf{A} + \Delta \mathbf{A})(\mathbf{x}+\Delta \mathbf{x}) = \mathbf{b}$, then
> $$
> \frac{\|\Delta \mathbf{x}\|}{\|\mathbf{x}\|} \le \kappa(\mathbf{A})\,\frac{\|\Delta \mathbf{A}\|}{\|\mathbf{A}\|},
> $$
> in the limit $\|\Delta \mathbf{A}\| \to 0$.

对任意诱导矩阵范数，我们总有

$$
1=\|\mathbf{I}\|=\|\mathbf{A}\mathbf{A}^{-1}\|\le \|\mathbf{A}\|\,\|\mathbf{A}^{-1}\|=\kappa(\mathbf{A}),
$$

因此 $\kappa(\mathbf{A})\ge 1$，而 $\kappa(\mathbf{A})=1$ 是能期待的最好情况.

如果 $\kappa(\mathbf{A})\approx 10^t$，那么在浮点数计算里，我们往往要为解 $\mathbf{x}$ 付出大约 $t$ 位有效数字的代价. 进一步地，如果 $\kappa(\mathbf{A}) > \epsilon_{\rm mach}^{-1}$，那么这种矩阵在计算意义下可以当成奇异的.

> **Demo:** Conditioning via Hilbert matrices and perturbation experiments.
> ```Python
> import numpy as np
>
> def hilbert_like(n):
>     i = np.arange(1, n + 1)[:, None]
>     j = np.arange(1, n + 1)[None, :]
>     return 1.0 / (i + j)
>
> rng = np.random.default_rng(0)
> eps_mach = np.finfo(float).eps
>
> # A 6x6 Hilbert-like matrix.
> A = hilbert_like(6)
> kappa = np.linalg.cond(A, 2)
> print("kappa =", kappa)
>
> # Engineer an exact solution.
> x = np.arange(1, 7, dtype=float)
> b = A @ x
>
> # Random perturbations of size 1e-10 in norm.
> dA = rng.standard_normal(A.shape)
> dA = 1e-10 * dA / np.linalg.norm(dA, 2)
> db = rng.standard_normal(b.shape)
> db = 1e-10 * db / np.linalg.norm(db)
>
> x_new = np.linalg.solve(A + dA, b + db)
> dx = x_new - x
> rel_err = np.linalg.norm(dx) / np.linalg.norm(x)
> print("relative error =", rel_err)
>
> bound_b = kappa * (np.linalg.norm(db) / np.linalg.norm(b))
> bound_A = kappa * (np.linalg.norm(dA, 2) / np.linalg.norm(A, 2))
> print("upper bound due to b =", bound_b)
> print("upper bound due to A =", bound_A)
>
> # Roundoff acts like a built-in perturbation at the eps_mach level.
> x_hat = np.linalg.solve(A, b)
> rel_err_round = np.linalg.norm(x_hat - x) / np.linalg.norm(x)
> rounding_bound = kappa * eps_mach
> print("roundoff relative error =", rel_err_round)
> print("kappa * eps_mach =", rounding_bound)
>
> # A larger case where kappa exceeds 1/eps_mach.
> A14 = hilbert_like(14)
> kappa14 = np.linalg.cond(A14, 2)
> x14 = np.arange(1, 15, dtype=float)
> b14 = A14 @ x14
> x14_hat = np.linalg.solve(A14, b14)
> rel_err14 = np.linalg.norm(x14_hat - x14) / np.linalg.norm(x14)
> print("kappa14 =", kappa14)
> print("kappa14 * eps_mach =", kappa14 * eps_mach)
> print("relative error (n=14) =", rel_err14)
> ```
> When $\kappa(\mathbf{A})$ is huge, large relative errors are unavoidable in floating-point arithmetic.

> **Note:** 这里 `np.linalg.cond(A, 2)` 用的是 2-norm 条件数. 不同库在数值细节上可能略有差异，但 "Hilbert 矩阵族条件数增长极快" 这一事实是稳定的.

> **Note:** 上面的扰动实验可以直接对照 **#2 主要结论** 里的不等式. 代码里先构造随机矩阵 $\mathbf{G}$ 与随机向量 $\mathbf{g}$，再做归一化
> $$
> \Delta \mathbf{A} = 10^{-10}\frac{\mathbf{G}}{\|\mathbf{G}\|_2},
> \qquad
> \Delta \mathbf{b} = 10^{-10}\frac{\mathbf{g}}{\|\mathbf{g}\|_2},
> $$
> 因此 $\|\Delta \mathbf{A}\|_2=\|\Delta \mathbf{b}\|_2=10^{-10}$. 然后解扰动后的系统 $(\mathbf{A}+\Delta \mathbf{A})\mathbf{x}_{\rm new}=\mathbf{b}+\Delta \mathbf{b}$，并比较
> $$
> \frac{\|\mathbf{x}_{\rm new}-\mathbf{x}\|}{\|\mathbf{x}\|}
> \quad\text{与}\quad
> \kappa(\mathbf{A})\frac{\|\Delta \mathbf{A}\|}{\|\mathbf{A}\|},\;
> \kappa(\mathbf{A})\frac{\|\Delta \mathbf{b}\|}{\|\mathbf{b}\|}.
> $$
> 对浮点舍入误差的那一段，可以把它理解成 "算法在机器里实际上解了一个被扰动过的系统"，典型的扰动尺度在 $\epsilon_{\rm mach}$ 附近，因此 $\kappa(\mathbf{A})\epsilon_{\rm mach}$ 是一个很有用的数量级指示.

**#3 残差与反向误差**

设 $\mathbf{A}\mathbf{x}=\mathbf{b}$ 的精确解为 $\mathbf{x}$，而 $\tilde{\mathbf{x}}$ 是某个数值算法给出的近似解. 我们最想研究的当然是正向误差 $\tilde{\mathbf{x}}-\mathbf{x}$，但它通常不可直接计算 (因为我们不知道 $\mathbf{x}$).

然而，我们可以计算一些与之相关的，例如残差.

> **Definition:** **Residual of a linear system.**
> For the problem $\mathbf{A}\mathbf{x} = \mathbf{b}$, the residual at a solution estimate $\tilde{\mathbf{x}}$ is
> $$
> \mathbf{r} = \mathbf{b}-\mathbf{A}\tilde{\mathbf{x}}.
> $$

如果 $\mathbf{r}=\mathbf{0}$，那么 $\tilde{\mathbf{x}}$ 就是精确解. 更一般地，由定义立刻得到

$$
\mathbf{A}\tilde{\mathbf{x}}=\mathbf{b}-\mathbf{r}.
$$

也就是说，$\tilde{\mathbf{x}}$ 是一个被扰动过的线性系统 (右端项从 $\mathbf{b}$ 变成 $\mathbf{b}-\mathbf{r}$) 的精确解. 因此在线性系统里，残差与反向误差是一回事.

残差与正向误差之间的关系可以用条件数连起来. 令 $\mathbf{h}=\tilde{\mathbf{x}}-\mathbf{x}$，则

$$
\mathbf{A}(\mathbf{x}+\mathbf{h})-\mathbf{b}=\mathbf{A}\mathbf{h}=-\mathbf{r}.
$$

把它代回前面 **#2 主要结论** 里的扰动不等式，就得到

$$
\frac{\|\tilde{\mathbf{x}}-\mathbf{x}\|}{\|\mathbf{x}\|}\le \kappa(\mathbf{A})\,\frac{\|\mathbf{r}\|}{\|\mathbf{b}\|}.
$$

这个式子说明：**相对误差与相对残差之间差了一个因子 $\kappa(\mathbf{A})$**. 因此，残差很小并不保证误差很小，它只能说明算法具有小的反向误差，而误差是否小还要看问题本身的条件数.

> **Observation:** When solving a linear system, all that can be expected is that the backward error, not the error, is small.

> **Note:** 解线性系统时，我们能期待的是 "残差相对大小" 小，即 $\|\mathbf{r}\|/\|\mathbf{b}\|$ 小. 正向误差的上界通常是 $\kappa(\mathbf{A})\cdot \|\mathbf{r}\|/\|\mathbf{b}\|$，因此当 $\kappa(\mathbf{A})$ 很大时，残差很小也可能对应很大的误差.
