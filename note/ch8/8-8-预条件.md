# 8-8-预条件 (Preconditioning)

这是一份数值计算学习笔记，参考了 Tobin A. Driscoll and Richard J. Braun 的教材 [*Fundamentals of Numerical Computation* (2023)](https://tobydriscoll.net/fnc-julia/home.html).

> 这份笔记主要是翻译了原文内容，并删改或重新表述部分内容，希望能进一步减少初学者的学习障碍.

**#1 为什么需要预条件**

MINRES 与 CG (以及更一般的 GMRES) 有一个很重要的性质: Krylov 子空间方法的收敛速度，往往会随着矩阵条件数的增大而变差. 即使条件数只是 "中等偏大"，也可能让收敛慢到不可用. 因此，这类方法在实际中常常需要配合一种技术，来降低 "与收敛相关的条件数". 这就是预条件 (preconditioning).

**#2 预条件的基本形式**

考虑线性系统

$$
\mathbf{A}\mathbf{x}=\mathbf{b}.
$$

预条件的基本想法是：通过一个矩阵 (或等价的线性变换) 去改写方程，使得改写后的系统对 Krylov 迭代而言 "更容易".

> **Definition:** Preconditioning
> Given a linear system $\mathbf{A}\mathbf{x}=\mathbf{b}$, a preconditioner is a matrix $\mathbf{M}$ or equivalent linear transformation that modifies the system to be
> $$
> (\mathbf{M}^{-1}\mathbf{A})\mathbf{x}=\mathbf{M}^{-1}\mathbf{b}.
> $$

上面的形式称为 left preconditioning (左预条件)，也是最常见、最简单的一类.

和前面一样，我们通常不希望真的为某个 $\mathbf{M}$ 去显式计算 $\mathbf{M}^{-1}$. 取而代之，我们是把问题看作 "在 Krylov 方法里需要反复计算 $\mathbf{M}^{-1}\mathbf{A}$ 作用在向量上". 这会把一次 "矩阵乘向量" 的操作拆成两步：

1. 先算 $\mathbf{y}=\mathbf{A}\mathbf{u}$.
2. 再解线性系统 $\mathbf{M}\mathbf{v}=\mathbf{y}$ 得到 $\mathbf{v}$.

> **Note:** 在实现上，Krylov 求解器通常接收的是 "如何做第 2 步" 的代码 (例如给定 $\mathbf{y}$，返回解 $\mathbf{v}$ ). 如果 $\mathbf{M}$ 以稀疏矩阵形式给出，一个常见默认策略是做一次稀疏分解，并用它反复做三角回代.

**#3 预条件的目标与权衡**

选择 $\mathbf{M}$ 时，会有两个互相拉扯的目标：

- 一方面，我们希望 $\mathbf{M}^{-1}\mathbf{A}\approx \mathbf{I}$，因为这会让预条件系统更容易被 Krylov 迭代求解，因此通常意味着 $\mathbf{M}\approx \mathbf{A}$.
- 另一方面，我们又希望解系统 $\mathbf{M}\mathbf{v}=\mathbf{y}$ 本身要足够快.

> **Observation:** Good preconditioning
> Good preconditioning is a matter of finding an easily inverted (i.e., quickly solvable) approximation of the original matrix.

**#4 对角预条件**

最简单的预条件之一，是让 $\mathbf{M}$ 成为一个对角矩阵. 这当然满足 "容易求逆"：因为解 $\mathbf{M}\mathbf{v}=\mathbf{y}$ 只需要逐分量相除：

$$
v_i=\frac{y_i}{M_{ii}}.
$$

关键问题在于：能否选出一个对角矩阵 $\mathbf{M}$，让 $\mathbf{M}^{-1}\mathbf{A}$ 比原来的 $\mathbf{A}$ 更适合 Krylov 迭代？当 $\mathbf{A}$ 的各行尺度差异很大，或 $\mathbf{A}$ 具有对角占优 (diagonally dominant) 结构时，答案往往是肯定的.

> **Demo:** Diagonal preconditioning in CG (SciPy)
> We build an SPD matrix from a PDE discretization and amplify row/column scale differences by diagonal scaling. Then we compare CG with and without a Jacobi (diagonal) preconditioner.
>
> ```Python
> import numpy as np
> import scipy.sparse as sp
> import scipy.sparse.linalg as spla
>
> def poisson_2d(n):
>     # Discrete 2D -Delta on an n-by-n interior grid, scaled by h^{-2}.
>     h = 1.0 / (n + 1)
>     e = np.ones(n)
>     T = sp.diags([-e, 4 * e, -e], [-1, 0, 1], shape=(n, n), format="csr") / (h * h)
>     I = sp.eye(n, format="csr")
>     S = sp.diags([-e, -e], [-1, 1], shape=(n, n), format="csr") / (h * h)
>     return (sp.kron(I, T) + sp.kron(S, I)).tocsr()
>
> n = 40
> A0 = poisson_2d(n)  # SPD
> N = A0.shape[0]
>
> # Diagonal scaling to create strong row/column scale differences while keeping SPD.
> s = np.logspace(0.0, 1.0, N)  # from 1 to 10
> D = sp.diags(s, 0, format="csr")
> A = (D @ A0 @ D).tocsr()
>
> x_true = np.ones(N)
> b = A @ x_true
>
> def run_cg(A, b, M=None, rtol=1e-8, maxiter=2000):
>     iters = 0
>     def cb(xk):
>         nonlocal iters
>         iters += 1
>     x, info = spla.cg(A, b, rtol=rtol, atol=0.0, maxiter=maxiter, M=M, callback=cb)
>     return iters, info
>
> it_plain, info_plain = run_cg(A, b, M=None)
>
> # Jacobi preconditioner: apply diag(A)^{-1} to a vector.
> Minv = 1.0 / A.diagonal()
> M = spla.LinearOperator(A.shape, matvec=lambda v: Minv * v, dtype=float)
> it_prec, info_prec = run_cg(A, b, M=M)
>
> print("plain: iters =", it_plain, "info =", info_plain)
> print("preconditioned: iters =", it_prec, "info =", info_prec)
> ```
>
> The diagonal preconditioner can reduce the iteration count substantially when the rows of `A` vary strongly in scale.

> **Note:** 在这个 Demo 里，$\mathbf{A}$ 仍然是 SPD，因此可以用 CG. 对角预条件并不保证一定有效，它更像是一种 "成本极低的第一尝试".

**#5 不完全分解**

另一个通用技术是 **不完全 LU 分解 (incomplete LU factorization)**. 稀疏矩阵做精确分解时，通常会出现大量 fill-in (原本为零的元素在分解中变成非零)，从而导致存储与计算代价暴涨. 不完全 LU 的思路是：允许分解不是精确的，通过丢弃小于某个阈值的元素来牺牲精度，以此控制因子矩阵的稀疏度.

下面的 Demo 展示了这个思路对 GMRES 的影响：无预条件时收敛很慢，而 iLU 作为预条件可以显著加速.

> **Demo:** Incomplete LU preconditioning for GMRES (SciPy)
> We solve a nonsymmetric sparse system with restarted GMRES (100 inner iterations). Then we add an iLU preconditioner built by `spilu`, and compare convergence and fill ratios.
>
> ```Python
> import numpy as np
> import scipy.sparse as sp
> import scipy.sparse.linalg as spla
>
> def advection_diffusion_2d(n, eps=1e-4, a=1.0, b=1.0, reaction=1.0):
>     # A simple nonsymmetric sparse matrix from a 2D advection-diffusion operator.
>     h = 1.0 / (n + 1)
>     e = np.ones(n)
>     T = sp.diags([e, -2 * e, e], [-1, 0, 1], shape=(n, n), format="csr") / (h * h)
>     I = sp.eye(n, format="csr")
>     Lap = sp.kron(I, T) + sp.kron(T, I)
>
>     # Upwind first derivative for positive velocities: (u_i - u_{i-1}) / h.
>     D1 = sp.diags([-e, e], [-1, 0], shape=(n, n), format="csr") / h
>     Dx = sp.kron(I, D1)
>     Dy = sp.kron(D1, I)
>
>     A = (-eps) * Lap + a * Dx + b * Dy + reaction * sp.eye(n * n, format="csr")
>     return A.tocsc()
>
> A = advection_diffusion_2d(60)
> N = A.shape[0]
> b = np.ones(N)
>
> def run_gmres(A, b, M=None, restart=50, cycles=2, rtol=1e-5):
>     hist = []
>     cb = lambda rn: hist.append(rn)
>     x, info = spla.gmres(
>         A, b, M=M, restart=restart, maxiter=cycles,
>         rtol=rtol, atol=0.0, callback=cb, callback_type="pr_norm",
>     )
>     relres = np.linalg.norm(b - A @ x) / np.linalg.norm(b)
>     return info, relres, np.array(hist)
>
> info0, rel0, hist0 = run_gmres(A, b, M=None)
> print("no preconditioner:", "info =", info0, "relres =", rel0)
>
> for drop_tol in [1e-1, 1e-2, 1e-3]:
>     ilu = spla.spilu(A, drop_tol=drop_tol, fill_factor=10)
>     M = spla.LinearOperator(A.shape, matvec=ilu.solve, dtype=float)
>     info, rel, hist = run_gmres(A, b, M=M)
>     ratio = (ilu.L.nnz + ilu.U.nnz) / A.nnz
>     print(f"iLU drop_tol={drop_tol:g}: info={info}, relres={rel:.2e}, fill_ratio={ratio:.2f}, iters={len(hist)}")
> ```
>
> Smaller `drop_tol` keeps more fill, which often reduces iteration count but increases per-iteration and setup costs.

> **Note:** 对 iLU 来说，关键不是 "把 $\mathbf{A}$ 分解得多精确"，而是 "它是否足够接近一个可快速求解的近似逆". 不同问题里，预条件的稀疏度 (fill) 与迭代次数之间的平衡点通常无法事先预测.

实践中，好的预条件往往和 (甚至比) 具体选 MINRES/CG/GMRES 更重要. 但有效预条件常常依赖对应用背景的理解：例如当线性系统来自某个连续模型的离散化时，我们可能用一个更粗的离散模型来构造 $\mathbf{M}$，从而得到一个自然的近似逆. Krylov 方法提供了一个统一的框架，把这类近似逆真正变成可用的加速器.
