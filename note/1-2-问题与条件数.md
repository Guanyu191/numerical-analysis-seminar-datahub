# 1-2-问题与条件数 (Problems and conditioning)

这是一份数值计算学习笔记，参考了 Tobin A. Driscoll and Richard J. Braun 的教材 [*Fundamentals of Numerical Computation* (2023)](https://tobydriscoll.net/fnc-julia/home.html).

> 这份笔记比较特殊，主要是翻译了原文内容，并删改或重新表述部分内容，希望能进一步减少初学者的学习障碍.

**#1 从 "加 1" 看 subtractive cancellation**

让我们先看一个看起来再简单不过的数学问题：把 1 加到一个数上. 形式化地，我们把它描述为函数 $f(x)=x+1$，其中 $x$ 是任意实数.

在计算机上，$x$ 会被它的浮点数表示 $fl(x)$ 代替. 之前 **1-1-浮点数** 提到：把实数舍入到最近的浮点数时，$x$ 到 $fl(x)$ 的距离至多是半个间距，因此我们可以写

$$
fl(x)=x(1+\epsilon), \qquad |\epsilon|\le \epsilon_{\rm mach}/2.
$$

表示常数 1 不会带来误差.

假设我们很幸运，加法本身没有引入额外误差，则机器给出的结果就是

$$
y=x(1+\epsilon)+1.
$$

因此相对误差为

$$
\frac{|y-f(x)|}{|f(x)|}
=\frac{|(x+\epsilon x+1)-(x+1)|}{|x+1|}
=\frac{|\epsilon x|}{|x+1|}.
$$

如果分母很小，这个误差就可能非常大. 事实上，只要取 $x$ 足够接近 $-1$，相对误差就可以任意大，这本质上就是 **1-1-浮点数** 里那个 "加法不满足结合律" 的 Demo 中发生的事：取 $e=\epsilon_{\rm mach}/2$，虽然 $(1+e)-1$ 与 $1+(e-1)$ 在数学上相等，但浮点运算会把它们算出不同结果 (一个是 0，另一个大约是 $10^{-16}$).

我们也可以用十进制有效数字直观地看到同样的问题. 例如，假设我们把所有结果都舍入到 5 位十进制有效数字，计算 $1.0000+(-1.0012)$ 得到 $-0.0012$ (也可写成 $-1.2\times 10^{-3}$). 注意：即使两个操作数都给到了 5 位十进制有效数字，在答案里写出超过两位有效数字也没有意义，因为输入本身并没有提供更多信息.

> **Note:** 这里说 "没有提供更多信息" 指的是，做加法的两个数 $1.0000$ 和 $-1.0012$ 只有 4 位小数，所以结果应该只关注到 $-0.0012$，而不会关注更多的小数位 (如 $-0.00120$).

这个现象称为 **subtractive cancellation**，也叫 **loss of significance**. 我们可以说，从 $-1.0012$ 到 $-0.0012$ 的映射中 "丢掉" 了 3 位有效数字. 一旦我们决定把所有量都舍入到固定的有效数字位数，这种损失就无法通过更换算法来避免.

> **Observation:** Subtractive cancellation
> Subtractive cancellation is a loss of accuracy that occurs when two numbers add or
> subtract to give a result that is much smaller in magnitude. It is one of the most
> common mechanisms introducing dramatic growth of errors in floating-point
> computation.

在双精度里，每个数通常能以大约 16 位十进制有效数字表示，但 **subtractive cancellation** 可能让其中一些位数变得 "没有信息量".

**#2 条件数 (Condition numbers)**

接下来我们更一般地看待 "问题". 和前面一样，我们把一个问题写成函数 $f$，它把实数数据 $x$ 映射到实数结果 $f(x)$. 可以简记为 $f:\mathbb{R}\mapsto\mathbb{R}$.

当问题 $f$ 在计算机上用浮点数近似时，数据 $x$ 会被浮点数 $\tilde{x}=fl(x)$ 代替. 如果忽略其他一切误差来源，我们定义下面这个量来衡量 "结果相对变化" 与 "数据相对变化" 的比值：

$$
\frac{\dfrac{|f(x)-f(\tilde{x})|}{|f(x)|}}{\dfrac{|x-\tilde{x}|}{|x|}}.
$$

> **Note:** 分子是结果的相对变化，分母是数据的相对变化. 我们用相对量，是为了让度量不依赖单位，也不被简单的尺度缩放影响.

它就是相对变化的放大倍数. 用 $\tilde{x}=x(1+\epsilon)$ (其中 $|\epsilon|\le \epsilon_{\rm mach}/2$) 代入，上式可以写得更方便：

$$
\frac{|f(x)-f(x+\epsilon x)|}{|\epsilon f(x)|}.
$$

最后，我们把理想化的 "完美计算机" 看作 $\epsilon_{\rm mach}\to 0$ 时的极限.

> **Definition:** Condition number (scalar function)
> The relative **condition number** $\kappa_f(x)$ of a scalar function $f(x)$ is
> $$
> \kappa_f(x)=\lim_{\epsilon\to 0}\frac{|f(x)-f(x(1+\epsilon))|}{|\epsilon f(x)|}.
> $$

> **Note:** 这个定义里，我们固定数据点 $x$，只看相对扰动 $x\mapsto x(1+\epsilon)$ 对结果的影响，并在 $\epsilon\to 0$ 的极限下提取一个 "局部放大倍数".

条件数是 **"输出相对误差"** 与 **"输入相对误差"** 的比值. 它只依赖于问题本身与给定的数据 $x$，而不依赖于计算机或算法.

假设 $f$ 至少有一阶连续导数，则可以把上面的极限化简为一个更直观的形式：

$$
\begin{align*}
\kappa_f(x)
&=\lim_{\epsilon\to 0}\left|\frac{f(x+\epsilon x)-f(x)}{\epsilon f(x)}\right|\\
&=\lim_{\epsilon\to 0}\left|\frac{f(x+\epsilon x)-f(x)}{\epsilon x}\cdot \frac{x}{f(x)}\right|\\
&=\left|\frac{x f'(x)}{f(x)}\right|.
\end{align*}
$$

> **Note:** 把 $f(x)=x+1$ 代入 $\kappa_f(x)=\left|\frac{x f'(x)}{f(x)}\right|$，得到 $\kappa_f(x)=\left|\frac{x}{x+1}\right|$. 因此 $x\approx -1$ 时条件数很大，这与前面相对误差公式的放大现象一致.

回头看，这个结论并不意外：$f(x)$ 的变化如何随 $x$ 的小变化而变，必然与导数 $f'(x)$ 有关. 如果我们用绝对变化 (而不是相对变化) 来度量，那么条件数就会简单地变成 $|f'(x)|$.

> **Example:** Let's return to our "add 1" problem and generalize it slightly to $f(x)=x-c$ for
> constant $c$. We compute
> $$
> \kappa_f(x)=\left|\frac{xf'(x)}{f(x)}\right|=\left|\frac{x}{x-c}\right|.
> $$
> The result is the relative change normalized by the size of the perturbation $\epsilon$.
> The condition number is large when $|x|\gg |x-c|$. Considering that $c$ can be
> negative, this result applies to both addition and subtraction. Furthermore, the addition
> situation is symmetric in $x$ and $c$; that is, if we perturbed $c$ and not $x$, the result
> would be $|c|/|x-c|$.

> **Example:** Another elementary operation is to multiply by a constant: $f(x)=cx$ for nonzero $c$.
> We compute
> $$
> \kappa_f(x)=\left|\frac{xf'(x)}{f(x)}\right|=\left|\frac{(x)(c)}{cx}\right|=1.
> $$
> We conclude that multiplication by a real number leads to the same relative error in the
> result as in the data. In other words, multiplication does not have the potential for
> cancellation error that addition does.

主要初等函数的条件数整理在下面的表格中. 另外，当 $h(x)=f(g(x))$ 时，复合函数的条件数满足链式法则：

$$
\kappa_h(x)=\kappa_f(g(x))\cdot \kappa_g(x).
$$

> **Table:** Relative condition numbers of elementary functions
> | Function | Condition number |
> | --- | --- |
> | $f(x)=x+c$ | $\kappa_f(x)=\dfrac{|x|}{|x+c|}$ |
> | $f(x)=cx$ | $\kappa_f(x)=1$ |
> | $f(x)=x^p$ | $\kappa_f(x)=|p|$ |
> | $f(x)=e^x$ | $\kappa_f(x)=|x|$ |
> | $f(x)=\sin(x)$ | $\kappa_f(x)=|x\cot(x)|$ |
> | $f(x)=\cos(x)$ | $\kappa_f(x)=|x\tan(x)|$ |
> | $f(x)=\log(x)$ | $\kappa_f(x)=\dfrac{1}{|\log(x)|}$ |

**#3 误差估计 (Estimating errors)**

回到 $\kappa_f$ 的定义，它本质上是一个 $\epsilon\to 0$ 的极限. 近似地说，当 $|\epsilon|$ 足够小时，我们期望

$$
\left|\frac{f(x+\epsilon x)-f(x)}{f(x)}\right|\approx \kappa_f(x)\,|\epsilon|.
$$

也就是说：只要数据 $x$ 被一个小的相对扰动改变，结果的相对变化大约会被放大 $\kappa_f(x)$ 倍.

> **Observation:** If $\kappa_f \approx 10^d$, then we expect to lose up to $d$ decimal digits of accuracy in computing $f(x)$ from $x$.

较大的条件数意味着：误差不再能被期望与舍入误差保持同一量级. 我们把 $\kappa_f(x)$ 很大的问题称为 **poorly conditioned** 或 **ill-conditioned**，但这个 "很大" 并没有固定阈值.

如果 $\kappa_f \approx 1/\epsilon_{\rm mach}$，那么仅仅因为我们用有限精度表示数据 $x$，结果就可能出现高达 100% 的相对误差. 在这个机器精度下，这样的函数几乎可以认为是不可计算的.

> **Note:** 把它理解成一个数量级判断：如果 $\kappa_f(x)\epsilon_{\rm mach}$ 已经接近 1，我们就不该期待在相对意义下还能得到稳定的有效数字. 想要更可信的结果，通常只能提高精度，或改用更合适的误差度量与问题表述.

> **Example:** Consider the problem $f(x)=\cos(x)$. By the table above, $\kappa_f(x)=|x\tan(x)|$. There
> are two different ways in which $\kappa$ might become large:
> - If $|x|$ is very large, then perturbations that are small relative to $x$ may still be
> large compared to 1. Because $|f(x)|\le 1$ for all $x$, this implies that the
> perturbation will be large relative to the result, too.
> - The condition number grows without bound as $x$ approaches an odd integer
> multiple of $\pi/2$, where $f(x)=0$. A perturbation which is small relative to a
> nonzero $x$ may not be small relative to $f(x)$ in such a case.

我们也可能注意到：对某些函数 (例如平方根)，条件数可以小于 1. 这意味着从输入到输出，相对变化反而变小了. 但浮点运算的每个结果仍然会在相对 $\epsilon_{\rm mach}$ 的水平上被舍入. 实践中，$\kappa_f<1$ 与 $\kappa_f=1$ 通常没有本质区别.

**#4 多项式求根 (Polynomial roots)**

多数实际问题都有多个输入和输出，这会让 "条件数" 的形式化定义变得更复杂. 不过我们仍然可以一次只看一个输出量如何随某个输入量变化，从而得到有用的局部结论.

> **Example:** Consider the problem of finding the roots of a quadratic polynomial; that is, the
> values of $x$ for which $ax^2+bx+c=0$. Here the data are the coefficients $a$, $b$, and $c$
> that define the polynomial, and the solution to the problem are the two (maybe
> complex-valued) roots $r_1$ and $r_2$. Formally, we might write $f([a,b,c])=[r_1,r_2]$ using
> vector notation.
>
> Let's pick one root $r_1$ and consider what happens to it as we vary just the leading
> coefficient $a$. This suggests a scalar function $f(a)=r_1$. Starting from
> $ar_1^2+br_1+c=0$, we differentiate implicitly with respect to $a$ while holding $b$ and $c$
> fixed:
> $$
> r_1^2+2ar_1\left(\frac{dr_1}{da}\right)+b\frac{dr_1}{da}=0.
> $$
> Solving for the derivative, we obtain
> $$
> \frac{dr_1}{da}=-\frac{r_1^2}{2ar_1+b}.
> $$
> Hence the condition number for the problem $f(a)=r_1$ is
> $$
> \kappa_f(a)=\left|\frac{a}{r_1}\cdot \frac{dr_1}{da}\right|
> =\left|\frac{ar_1}{2ar_1+b}\right|
> =\left|\frac{r_1}{r_1-r_2}\right|,
> $$
> where in the last step we used the quadratic formula:
> $$
> |2ar_1+b|=\sqrt{b^2-4ac}=|a(r_1-r_2)|.
> $$
> Based on the expression above, we can expect poor conditioning in the rootfinding problem if and
> only if $|r_1|\gg |r_1-r_2|$. Similar conclusions apply for $r_2$ and for variations with
> respect to the coefficients $b$ and $c$.

上面的计算可以推广到更高次多项式.

> **Observation:** Roots of polynomials are ill-conditioned with respect to changes in the polynomial
> coefficients when they are much closer to each other than to the origin.

> **Note:** 直觉上，系数是 "输入"，根是 "输出"，因为问题是：已知多项式系数，求多项式的根，那么这个流程就是 "系数 -> 根". 当两根彼此非常接近时，要把它们区分开就需要极其精细的系数信息，因此系数里一点点相对误差都可能导致根的位置出现很大的相对变化.

根的条件数可以任意大. 在极端情形下，如果出现重根，那么条件数形式上会变为无穷大，这意味着 "根的变化" 相对于 "系数的变化" 的比值无法被统一上界控制.

> **Demo:** Nearby roots of a quadratic.
> ```Python
> import numpy as np
>
> eps = 1e-6
>
> # p(x) = (1/3) (x - 1) (x - 1 - eps)
> a = 1 / 3
> b = (-2 - eps) / 3
> c = (1 + eps) / 3
>
> disc = np.sqrt(b * b - 4 * a * c)
> r1 = (-b - disc) / (2 * a)
> r2 = (-b + disc) / (2 * a)
> print("roots =", (r1, r2))
>
> relerr = abs(r2 - (1 + eps)) / (1 + eps)
> print("relative error in r2 =", relerr)
>
> print("epsmach / eps =", np.finfo(float).eps / eps)
> ```
> You should see that the relative error in $r_2$ is on the order of `epsmach / eps`.

> **Note:** 当两根的间距只有 $O(\epsilon)$ 时，根的条件数会与 $1/\epsilon$ 同阶，因此系数里的舍入误差可以被放大到大约 $\epsilon_{\rm mach}/\epsilon$ 的相对量级.
