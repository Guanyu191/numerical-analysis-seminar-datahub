# 3-1-用函数拟合数据 (Fitting functions to data)

这是一份数值计算学习笔记，参考了 Tobin A. Driscoll and Richard J. Braun 的教材 [*Fundamentals of Numerical Computation* (2023)](https://tobydriscoll.net/fnc-julia/home.html).

> 这份笔记主要是翻译了原文内容，并删改或重新表述部分内容，希望能进一步减少初学者的学习障碍.

**#1 插值不一定合适**

在 **2-1-多项式插值** 里，我们用一个多项式去插值一组数据，也就是构造一个连续函数，使得它在每个给定自变量处的取值，恰好等于对应的观测值. 但在数据量较多的时候，插值并不一定合适.

下面用一组全球气温的数据作为例子. 这些数是 "相对于 1951–1980 年平均值的全球温度 **距平** 的 5 年平均值" (数据来源: NASA). 我们先用一个多项式插值函数去拟合这些数据点.

> **Note:** 这里的 **"温度距平 (temperature anomaly)"** 指的是相对于基准期 (1951–1980) 全球平均温度的偏差
> $$
> a(t)=T_{\text{global}}(t)-\overline{T}_{1951\text{–}1980}.
> $$
> 因此，距平为正表示该时期比基准期更暖，距平为负表示更冷. 这里的数值为 5 年平均距平，用于平滑年际波动.

> **Note:** 在构造 Vandermonde 矩阵之前，我们先把时间改写为 "距 1950 的十年数"，这样可以显著改善矩阵的条件数.

> **Demo:** Interpolating the temperature anomaly data with a polynomial.
> ```Python
> import numpy as np
> import matplotlib.pyplot as plt
> from numpy.polynomial import Polynomial
>
> year = np.arange(1955, 2001, 5)
> temp = np.array([
>     -0.0480, -0.0180, -0.0360, -0.0120, -0.0040,
>      0.1180,  0.2100,  0.3320,  0.3340,  0.4560,
> ])
>
> plt.scatter(year, temp, label="data")
> plt.xlabel("year")
> plt.ylabel("anomaly (degrees C)")
>
> # Rescale time: decades since 1950.
> t = (year - 1950) / 10
> n = len(t)
>
> # Vandermonde matrix for interpolation: powers 0..n-1.
> V = np.vander(t, N=n, increasing=True)
> c = np.linalg.solve(V, temp)
>
> p = Polynomial(c)
> def f(yr):
>     return p((yr - 1950) / 10)
>
> grid = np.linspace(year[0], year[-1], 400)
> plt.plot(grid, f(grid), label="interpolant")
> plt.legend()
> plt.show()
> ```
> The interpolant matches all data points exactly, but the resulting curve can be wildly oscillatory.

尽管插值多项式确实 "穿过" 了所有数据点，但在 "温度" 这个实际意义下，拟合的结果看起来非常不自然，因为两端出现强烈振荡. 这种为了把每个点都拟合到完全一致而导致曲线形态变得离谱的现象，通常称为 **overfitting**.

如果我们的目标不是完全复现每个数据点，而是用一个更平滑的函数去抓住整体趋势，那么更好的做法是 **"放松插值的要求"**. 在多项式的情形下，这通常意味着降低多项式的次数.

令 $(t_i, y_i)$ (对 $i=1,\dots,m$) 为给定的数据点. 我们用一个次数为 $n-1$ 的多项式去表示这些数据：

$$
y \approx f(t) = c_1 + c_2 t + \cdots + c_n t^{\,n-1},
$$

其中 $n<m$. 这和 **2-1-多项式插值** 里的 Vandermonde 表达类似，我们可以把所有 $y$ 值写成一个矩阵与系数向量的乘积，但由于 $n<m$，我们只能找一个近似

$$
\begin{bmatrix}
y_1\\
y_2\\
\vdots\\
y_m
\end{bmatrix}
\approx
\begin{bmatrix}
1 & t_1 & \cdots & t_1^{n-1}\\
1 & t_2 & \cdots & t_2^{n-1}\\
\vdots & \vdots & & \vdots\\
1 & t_m & \cdots & t_m^{n-1}
\end{bmatrix}
\begin{bmatrix}
c_1\\
c_2\\
\vdots\\
c_n
\end{bmatrix}
=\mathbf{V}\mathbf{c},
$$

其中 $\mathbf{V}\in\mathbb{R}^{m\times n}$ 是一个 "Vandermonde-like" 的矩阵. 它的结构和 Vandermonde 矩阵一样，但这里 $n<m$，因此它是一个 "高高瘦瘦的矩阵". 一般来说，我们不可能用 $n$ 个变量去同时满足 $m$ 条方程，所以这个线性系统是 **overdetermined (超定)** 的.

**既然不能精确求解，我们就需要定义什么叫 "最好的近似解"**，并设法把它算出来. 在继续之前，我们先看一个最常见的例子：用一条直线做最小二乘拟合.

> **Demo:** A best-fit line via least squares.
> ```Python
> import numpy as np
> import matplotlib.pyplot as plt
> from numpy.polynomial import Polynomial
>
> year = np.arange(1955, 2001, 5)
> temp = np.array([
>     -0.0480, -0.0180, -0.0360, -0.0120, -0.0040,
>      0.1180,  0.2100,  0.3320,  0.3340,  0.4560,
> ])
> t = (year - 1950) / 10
>
> # Linear polynomial f(t) = c0 + c1 t.
> V = np.column_stack([np.ones_like(t), t])
> c, *_ = np.linalg.lstsq(V, temp, rcond=None)
> print("c =", c)
>
> p = Polynomial(c)
> def f(yr):
>     return p((yr - 1950) / 10)
>
> plt.scatter(year, temp, label="data")
> grid = np.linspace(year[0], year[-1], 400)
> plt.plot(grid, f(grid), label="linear fit")
> plt.xlabel("year")
> plt.ylabel("anomaly (degrees C)")
> plt.legend()
> plt.show()
> ```
> `np.linalg.lstsq` returns the least-squares solution when the system is overdetermined.

> **Note:** 在 Python 里，如果矩阵是方阵且可逆，我们通常用 `np.linalg.solve` 解线性系统. 如果矩阵是高矩阵 (超定)，我们通常用 `np.linalg.lstsq` 求最小二乘意义下的解.

如果把拟合多项式从一次提高到三次，数据点会被更紧密地贴住. 我们只需要把矩阵 $\mathbf{V}$ 的列数从 2 提高到 4 (对应 $1,t,t^2,t^3$)，再做一次最小二乘求解.

> **Demo:** A global cubic polynomial fit via least squares.
> ```Python
> import numpy as np
> import matplotlib.pyplot as plt
> from numpy.polynomial import Polynomial
>
> year = np.arange(1955, 2001, 5)
> temp = np.array([
>     -0.0480, -0.0180, -0.0360, -0.0120, -0.0040,
>      0.1180,  0.2100,  0.3320,  0.3340,  0.4560,
> ])
> t = (year - 1950) / 10
>
> # Cubic polynomial f(t) = c0 + c1 t + c2 t^2 + c3 t^3.
> V = np.vander(t, N=4, increasing=True)
> c, *_ = np.linalg.lstsq(V, temp, rcond=None)
> p = Polynomial(c)
>
> def f(yr):
>     return p((yr - 1950) / 10)
>
> plt.scatter(year, temp, label="data")
> grid = np.linspace(year[0], year[-1], 400)
> plt.plot(grid, f(grid), label="cubic fit")
> plt.xlabel("year")
> plt.ylabel("anomaly (degrees C)")
> plt.legend()
> plt.show()
> ```
> Increasing the degree usually decreases residuals at the data points, but it can also increase overfitting.

如果我们继续提高多项式次数，数据点处的 **residual** 会变得更小，但 **overfitting** 也会更严重.

**#2 最小二乘的线性代数表述**

更一般地，我们把拟合函数 $f(t)$ 写成

$$
f(t)=c_1 f_1(t)+\cdots+c_n f_n(t),
$$

其中 $f_1,\dots,f_n$ 都是已知函数，不包含待定参数. 因此未知量只剩下 $c_1,\dots,c_n$.

> **Note:** 注意，我们这里说的 "线性"，是 **对系数 $c_1,\dots,c_n$ 线性**，至于 $f_1,\dots,f_n$ 只要与系数无关就行，我们习惯将 $f_i$ 看作 "基".

线性最小二乘问题的关键特征是：拟合结果只以线性的方式依赖这些未知参数. 

> **Note:** 例如，形如 $f(t)=c_1 + c_2 e^{c_3 t}$ 的函数就不属于这一类，因为 $c_2$ 和 $c_3$ 混在一起了，$f(t)$ 对参数的依赖是非线性的.

对每个观测点 $(t_i,y_i)$，我们定义一个残差

$$
r_i = y_i - f(t_i).
$$

一个自然的拟合准则是，让所有 **残差的平方和尽可能小**. 也就是在所有参数 $c_1,\dots,c_n$ 的选择中，最小化

$$
R(c_1,\dots,c_n)=\sum_{i=1}^{m}\left[y_i-f(t_i)\right]^2.
$$

我们可以用线性代数把它写成向量形式，令

$$
\mathbf{r}=
\begin{bmatrix}
y_1\\
y_2\\
\vdots\\
y_m
\end{bmatrix}
-
\begin{bmatrix}
f_1(t_1) & f_2(t_1) & \cdots & f_n(t_1)\\
f_1(t_2) & f_2(t_2) & \cdots & f_n(t_2)\\
\vdots & \vdots & & \vdots\\
f_1(t_m) & f_2(t_m) & \cdots & f_n(t_m)
\end{bmatrix}
\begin{bmatrix}
c_1\\
c_2\\
\vdots\\
c_n
\end{bmatrix},
$$

那么目标函数就是

$$
R=\mathbf{r}^{T}\mathbf{r}=\|\mathbf{r}\|_2^2.
$$

把变量重命名成更标准的符号，我们就得到线性最小二乘问题的一般形式.

> **Definition:** Linear least-squares problem
> Given $\mathbf{A}\in\mathbb{R}^{m\times n}$ and $\mathbf{b}\in\mathbb{R}^{m}$, with $m>n$, find
> $$
> \operatorname*{argmin}_{\mathbf{x}\in\mathbb{R}^{n}} \|\mathbf{b}-\mathbf{A}\mathbf{x}\|_2^2.
> $$

> **Note:** 这里的 `argmin` 表示：找出使目标函数取到最小值的那个 $\mathbf{x}$. 虽然我们也可以用其他向量范数来定义 "最小"，但 2-范数是最常见也最方便的选择. 在本章后续内容里，我们只使用 2-范数.

> **Note:** 在一个极端的情形里，线性最小二乘问题会退化成线性系统问题：当 $m=n$ 且 $\mathbf{A}$ 非奇异时，如果 $\mathbf{A}\mathbf{x}=\mathbf{b}$ 可解，那么残差向量 $\mathbf{r}=\mathbf{0}$，因此 $\|\mathbf{r}\|_2^2=0$，这当然是一个全局最小值 (因为 $\|\mathbf{r}\|_2^2\ge 0$).

**#3 变量代换**

多项式最小二乘里最熟悉的情形就是直线拟合：

$$
f(t)=c_1+c_2 t.
$$

有些其他形式的拟合函数，也可以通过 **变量代换** 变成这种 "拟合直线" 的线性问题.

例如，我们想用指数函数

$$
g(t)=a_1 e^{a_2 t}
$$

去拟合数据，但显然 $g$ 对 $a_1, a_2$ 不是线性的，此时我们可以取对数，

$$
\log y \approx \log g(t) = (\log a_1)+a_2 t = c_1 + c_2 t.
$$

把 $\log y$ 作为新的因变量后，它对 $c_1, c_2$ 是线性的，而且 $c_1, c_2$ 可以唯一地对应到 $a_1, a_2$，所以我们实际上是在做线性拟合.

类似地，幂律关系

$$
y \approx a_1 t^{a_2}
$$

等价于

$$
\log y \approx (\log a_1) + a_2 (\log t).
$$

> **Note:** 上面的对数变换默认要求 $y>0$ 且 $t>0$，否则 $\log$ 没有定义 (或需要进入复数域).

下面的例子展示了：我们可以用最小二乘，把一个收敛误差序列拟合成幂律，并从 log-log 图上估计收敛速率.

> **Demo:** Fitting a power law to a convergence curve.
> ```Python
> import numpy as np
> import matplotlib.pyplot as plt
>
> # pi^2/6 = sum_{k>=1} 1/k^2.
> k = np.arange(1, 101)
> s = np.cumsum(1 / k**2)
> p = np.sqrt(6 * s)              # p_k
>
> eps = np.abs(np.pi - p)         # epsilon_k
>
> plt.figure()
> plt.scatter(k, p, s=12)
> plt.title("Sequence convergence")
> plt.xlabel("k")
> plt.ylabel("p_k")
>
> plt.figure()
> plt.scatter(k, eps, s=12)
> plt.title("Convergence of errors")
> plt.xlabel("k")
> plt.ylabel("error")
> plt.xscale("log")
> plt.yscale("log")
>
> # Fit log(eps) ≈ log(a) + b log(k).
> V = np.column_stack([np.ones_like(k), np.log(k)])
> c, *_ = np.linalg.lstsq(V, np.log(eps), rcond=None)
> a, b = np.exp(c[0]), c[1]
> print("b =", b)
>
> plt.plot(k, a * k**b, linestyle="--", label="power-law fit")
> plt.legend()
> plt.show()
> ```
> On the log-log scale, a straight line indicates a power law `eps_k ≈ a k^b`.

> **Note:** 这里说明了，变量 $z=\log y$ 可以作为变量 $s=\log t$ 的线性函数来拟合. 

> **Note:** 通常地，指数拟合适合用 log-linear 图，幂律拟合适合用 log-log 图.
